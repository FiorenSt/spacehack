{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next-Generation Astronomical Transient Classification via Large Language Models\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/turanbulmus/spacehack/blob/main/01%20-%20Prompt%20Engineering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fturanbulmus%2Fspacehack%2Fmain%2F01%20-%20Prompt%20Engineering.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/turanbulmus/spacekhack/main/01%20-%20Prompt%20Engineering.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/turanbulmus/spacehack/blob/main/01%20-%20Prompt%20Engineering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Author(s) | turanbulmus\n",
    "https://github.com/turanbulmus |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook showcases the potential of multimodal models like Gemini 1.5 Pro for tackling zero-shot object classification problems. We'll explore how this advanced model can analyze telescope images, compare them against reference and difference images, and classify them as \"real\" or \"bogus\" solely based on visual information and human-provided instructions. By the end of this notebook, you'll gain insights into:\n",
    "\n",
    "* How Gemini 1.5 Pro can perform zero-shot classification tasks without explicit training.\n",
    "* The power of multimodal models to understand and reason about visual content.\n",
    "* Building effective prompts for complex image analysis tasks.\n",
    "\n",
    "This notebook demonstrates the following steps:\n",
    "\n",
    "1. **Import Libraries and Build Functions:** We start by importing the necessary libraries for image loading, processing, and evaluation. We also define functions to facilitate the analysis and visualization of results.\n",
    "2. **Build System Instructions for the Prompt:** A well-crafted prompt is crucial for guiding Gemini 1.5 Pro towards the desired output. We carefully define instructions outlining the task, the type of images, and the desired classification outcome.\n",
    "3. **Load the Dataset:** We load a collection of telescope images, including reference, difference, and new images, to be used for the classification task.\n",
    "4. **Run Gemini 1.5 Pro with the Prompt:** We execute the prompt with Gemini 1.5 Pro, iterating over 100 samples from the dataset to get classifications for each image.\n",
    "5. **Evaluate Model Performance:** We evaluate the model's performance using metrics like a confusion matrix, precision, recall, and accuracy. These metrics provide insights into the model's ability to correctly classify \"real\" and \"bogus\" images. Finally, we visualize the results for better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate your notebook environment\n",
    "\n",
    "If you're using Colab, run the code in the next cell. Follow the popups and authenticate with an account that has access to your Google Cloud [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects).\n",
    "\n",
    "If you're running this notebook somewhere besides Colab, make sure your environment has the right Google Cloud access. If that's a new concept to you, consider looking into [Application Default Credentials for your local environment](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev) and [initializing the Google Cloud CLI](https://cloud.google.com/docs/authentication/gcloud). In many cases, running `gcloud auth application-default login` in a shell on the machine running the notebook kernel is sufficient.\n",
    "\n",
    "More authentication options are discussed [here](https://cloud.google.com/docs/authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    print('Authenticated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Google Cloud environment variables information and initialize Clients\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and the following:\n",
    "* [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). \n",
    "* [Enable the Big Query API](https://console.cloud.google.com/flows/enableapi?apiid=bigquery.googleapis.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-64c57809-e493-4d5f-9492-b3f421a0ecbd\" href=\"#view-view-vertex-resource-64c57809-e493-4d5f-9492-b3f421a0ecbd\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-64c57809-e493-4d5f-9492-b3f421a0ecbd');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/supernovadetection/runs?project=turan-genai-bb');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/supernovadetection/runs?project=turan-genai-bb', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJECT_ID = \"turan-genai-bb\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "EXPERIMENT_NAME = \"supernovadetection\" # @param {type:\"string\"}\n",
    "# Make sure that dataset is created in Big Query\n",
    "DATASET_ID = \"spacehack\" # @param {type:\"string\"}\n",
    "import vertexai\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, experiment=EXPERIMENT_NAME)\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown \n",
    "import base64\n",
    "import json\n",
    "import random\n",
    "import time, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason, Image\n",
    "from google.cloud import bigquery\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "from helper_functions import build_run_batch, if_tbl_exists, create_ex, save_picture, save_prompt, build_experiment_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the system instructions\n",
    "PERSONA = \"\"\"<PERSONA>\n",
    "You are an experienced astrophysicist, and your task is to classify astronomical transients into Real or Bogus based on a given set of 3 images. You have seen thousands of astronomical images during your lifetime and you are very good at making this classification by looking at the images and following the instructions. \n",
    "</PERSONA>\"\"\"\n",
    "\n",
    "INSTRUCTIONS = \"\"\"\\n<INSTRUCTIONS>\n",
    "**1. Purpose**\n",
    "This guide is designed to help vet astronomical data for the Real/Bogus classification. The goal is for you to learn how to distinguish between real and bogus sources. \n",
    "\n",
    "**2. Information Provided**\n",
    "You will be shown three astronomical image cutouts:\n",
    "a) **New Image:** The newest fully reduced science image centred at the location of the suspected transient source. \n",
    "b) **Reference Image:** A reference image from the same telescope of the same part of the sky to be used for comparison. It shows if the source was already there in the past or not.\n",
    "c) **Difference Image:** The residual image after the new and reference images are subtracted (sky-subtracted and scaled/convolved to match PSFs). Real sources should appear in this cutout as circular objects with positive (or negative) flux. Imperfect astrometric regridding can cause ‘ying-yang’ patterns of positive and negative flux at the same time. If the source of interest at the centre of the cutout presents this feature it is to be considered as Bogus.\n",
    "\n",
    "**3. Real and Bogus Sources**\n",
    "To classify the sources, you need to understand what constitutes a real or bogus source: \n",
    "\n",
    "**Real Source** \n",
    "A real source is any astrophysical origin that is variable in time. Characteristics of a real source include: \n",
    "a) **Shape:** The source at the centre appears as a point source with a circular shape and a visual extent of ~5-10 pixels, varying with focus conditions. \n",
    "b) **Brightness:** The source at the centre is positive in either the new or reference image. \n",
    "c) **Variability:** The source at the centre can fade or brighten between the new and reference image, appearing as positive or negative in the difference image. \n",
    "d) **Presence:** The source may (dis)appear between the new and reference image. It can happen that there is no source in one image and a clear point-source in the other. It can also occur that a source appears on top of an underlying galaxy (e.g. SN). \n",
    "\n",
    "**Bogus Source** \n",
    "A bogus source is any source not of astrophysical origin, such as detector artefacts, cosmic rays, reflections, data processing errors, cross-talk, or diffraction spikes. \n",
    "Characteristics of a bogus source include: \n",
    "a) **Shape:** The source at the centre is not circular (e.g., elongated) with a size <5 pixels or >10 pixels. A single bright pixel is not a point-source (likely a cosmic-ray). This also includes irregular shapes like streaks or lines caused by cross-talk or diffraction spikes. \n",
    "b) **Brightness:** The source at the centre is negative (dark) in either the new or reference image. The source at the centre of the cutouts can never be negative in the new or reference image. \n",
    "c) **Artifacts:** The source at the centre is simply a detector artifacts such as reflections,  cross-talk, and dead pixels. Diffraction spikes from nearby bright stars or other optical effects can also create potential Bogus sources. \n",
    "d) **Misalignment** If the source in the New and Reference image are misaligned it will show a Yin Yang pattern in the difference image, this is a Bogus.\n",
    " \n",
    "**4. Additional Guidance** \n",
    "a) **Contextual Information:** The classification in Real or Bogus is for the source at the centre of the cutours, but keep in mind that sources nearby can help is diagnose problems in the difference image.  \n",
    "b) **Examples:** Refer to provided visual examples of real and bogus sources to aid in identification. \n",
    "c) **Judgment Criteria:** For ambiguous cases or borderline scenarios, consider the overall context and consistency with known characteristics of real and bogus sources. \n",
    "\n",
    "**5. Misalignment of real image and reference image**\n",
    "If New and Reference image present a realistic source but the difference image have a Yin Yang pattern, this is a Bogus. It is simply due to a misalignment of the New and Reference image.\n",
    "</INSTRUCTIONS> \"\"\"\n",
    "\n",
    "TASK = \"\"\"<TASK>\n",
    "Your task is to read the INSTRUCTIONS, look at the 3 images (New, Reference and Difference images) and classify if the source at the centre is a Real or Bogus astronomical transient. Provide your thought process to explain how you reasoned to provide the response. Respond in json format. \n",
    "</TASK>\\n\n",
    "\"\"\"\n",
    "\n",
    "METHOD = \"\"\"<METHOD>\n",
    "Do not simply provide a binary classification. Utilize your knowledge, the provided guide, and the image data to generate a comprehensive explanation for your classification.\n",
    "Base your reasoning by only looking at the center of the image. The images are prepared specifically so that the questioned light source sits at the center of the image.\n",
    "Employ a chain-of-thought process, clearly outlining each step of your analysis.\n",
    "Analyze each image individually and in relation to each other.\n",
    "For each feature you examine (shape, flux, etc.), describe your observations and how they contribute to your classification.\n",
    "If you observe features from the images described in the <INSTRUCTIONS> section, clearly identify them and relate them to your reasoning.\n",
    "If any of your observations contradict a potential classification, acknowledge the discrepancy and justify your final decision.\n",
    "</METHOD>\n",
    "\"\"\"\n",
    "# Collapse the System Instructions into a single variable\n",
    "stat_prompt = PERSONA + INSTRUCTIONS + METHOD + TASK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt examples Build\n",
    "\n",
    "file_path_data = 'data/new_data.npy'\n",
    "file_path_labels = 'data/new_labels.npy'\n",
    "\n",
    "# Load the .npy file containing the quadruplets of images\n",
    "id = \"1BYcdnknvUh7Ghe-zb5LfViyfak7YjF-Y\" #id from the Google Drive\n",
    "#gdown.download(id=id, output = file_path_data)\n",
    "# Load the .npy file containing the labels\n",
    "id =  \"1--_6XLpz-NWddPZ_HegWvaPpzBDlQPwy\" #id from the Google Drive\n",
    "#gdown.download(id=id, output = file_path_labels)\n",
    "\n",
    "\n",
    "quadruplets = np.load(file_path_data)\n",
    "\n",
    "# Load the labels and create index\n",
    "labels = np.load(file_path_labels)\n",
    "index = np.arange(stop=len(labels), dtype=int)\n",
    "\n",
    "# Combine the index and label arrays using 'zip' and convert to a NumPy array\n",
    "labels_with_index = np.array(list(zip(index, labels)), dtype='object')\n",
    "labels_df = pd.DataFrame(labels_with_index, columns=[\"index_no\", 'label'])\n",
    "labels_df['label'] = labels_df['label'].apply(lambda x: 'Real' if x > 0.5 else 'Bogus')\n",
    "\n",
    "\n",
    "# Upload Labels to Big Query Check if the table exists\n",
    "labels_id = \"labels_df\"\n",
    "# Construct the table reference\n",
    "labels_ref = bq_client.dataset(DATASET_ID).table(labels_id)\n",
    "# Creates the if it doesnt exists.\n",
    "create_table_flag = if_tbl_exists(bq_client, labels_ref)\n",
    "# Upload labels_df to Big Query\n",
    "if create_table_flag != True:\n",
    "    bq_client.load_table_from_dataframe(labels_df,labels_ref)\n",
    "\n",
    "# Sample indexes you want to access and save them as files so that sent to Gemini\n",
    "sample_indexes = [0, 1, 3, 4, 8, 48, 77,  1179,  1180,  1181,  1191, 1193, 592, 685]\n",
    "train_labels_id = \"1-4HSiQWPjJYinhYrq-nw33eY-3SzZXqz\"\n",
    "train_data_id = \"1--yYNr67knDfqiTHJe8bjaBjRoq2GjUP\"\n",
    "train_data_path = \"data/pics/prompt_pics/train_data.npy\"\n",
    "train_label_path = \"data/pics/prompt_pics/train_label.npy\"\n",
    "#gdown.download(id=train_data_id, output = train_data_path)\n",
    "#gdown.download(id=train_labels_id, output = train_label_path)\n",
    "\n",
    "train_data = np.load(train_data_path)\n",
    "for i in sample_indexes:\n",
    "    save_picture(train_data, i, True)\n",
    "\n",
    "# For the dynamic part of the prompt generate and save the pictures in a folder\n",
    "batch_index = index \n",
    "for t in batch_index:\n",
    "    save_picture(quadruplets, t, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DESCRIPTION INDEX 0:\n",
    "desc1 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"A diffraction spike is present in all three images. No circular source is found at the center of the New or Reference image; this is a bogus source.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 1:\n",
    "desc2 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"The New image has a negative artefact at its center (not to be confused with the source slightly off-centre), so it is not a real source. A negative artefact in the New image can create a misleading negative source that could look like a real source that got dimmer, however remember that the source can never be negative in the New image.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 3:\n",
    "desc3 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"In the New image the source is a streak of few really bright pixels and not circular. No source at the same location (center of the cutout)  in the Reference image. This is too sharp to be a real source and most likely a cosmic ray.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 4:\n",
    "desc4 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"In the Reference image the source is a streak of few really bright pixels and not circular. No source at the same location (center of the cutout)  in the New image. This is too sharp to be a real source and most likely a cosmic ray that was not flagged during the Reference images creation.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 8:\n",
    "desc5= {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"No source seems to be present in the New image. In the Reference image, the source appears as a negative circular object, and therefore this cannot be real. It is most likely a lump of dead pixels that have gone unflagged during the reference image creation.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 48:\n",
    "desc6 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"There is a really faint source in the New image. The Reference image has an elongated source that is likely not a real source. A negative elongated source appears in the Difference image, confirming this is not a real source.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 77:\n",
    "desc7 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"In both the New and Reference images, there is the same central source (and a bunch of other sources around). However, in the Difference image, there are clear Yin-Yang patterns, suggesting that the reason why the source is suspected to be a transient is only due to misalignment.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 1179:\n",
    "desc8 = {\n",
    "  \"class\": \"Real\",\n",
    "  \"explanation\": \"The source is present at the same location in all three images. The Difference image shows a positive residual signifying that the source is likely a variable star and it has brightened.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 1180:\n",
    "desc9 = {\n",
    "  \"class\": \"Real\",\n",
    "  \"explanation\": \"The source is present at the same location in all three images. The Difference image shows a negative residual, signifying that the source is likely a variable star that has dimmed.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 1181:\n",
    "desc10 = {\n",
    "  \"class\": \"Real\",\n",
    "  \"explanation\": \"In the New image there is no source at the center of the cutout. The Reference image however presents a good circular source at its center. This leaves a negative, point-source-like object in the Difference image, as expected from a transient that disappeared.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 1191:\n",
    "desc11 = {\n",
    "  \"class\": \"Real\",\n",
    "  \"explanation\": \"There is a bright circular source in the center of the New image. No source can be seen at the same central location in the Reference image. The Difference image has a positive circular source as expected from a real (explosive) transient.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 1193:\n",
    "desc12 = {\n",
    "  \"class\": \"Real\",\n",
    "  \"explanation\": \"The source is present at the same location in all three images. The Difference image shows a positive residual signifying that the source is likely a variable star and it has brightened. The cutouts also show a cosmic ray on the left of the source, however, the central source is a good transient, and we can disregard the artefact.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 592:\n",
    "desc13 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"A diffused source is at the centre of the New image, aligned with the 45-degree diffraction spike of a bright source at the cutout corner. The Reference image also shows a similar diffraction spike and blob. The Difference image displays a positive blob, which is a bogus source caused by the diffraction spike. Diffraction spikes can sometimes appear with blobs or irregularities instead of straight lines.\"\n",
    "}\n",
    "\n",
    "## DESCRIPTION INDEX 685:\n",
    "desc14 = {\n",
    "  \"class\": \"Bogus\",\n",
    "  \"explanation\": \"There is no source at the centre of the New image. The Reference image shows a faint positive trail cutting diagonally across the image with a circular source at its centre. This is likely an artefact caused by a faint blinking object such as an airplane or satellite. The Difference image displays both the trail and a negative blob, confirming a bogus source of non-astronomical origin.\"\n",
    "}\n",
    "\n",
    "descriptions = [str(desc1), str(desc2), str(desc3), str(desc4), str(desc5), str(desc6),str(desc7), str(desc8), str(desc9), str(desc10), str(desc11), str(desc12), str(desc13), str(desc14)]\n",
    "\n",
    "### Write the examples used in a readable format to be saved as a txt file for tracebility\n",
    "example_description = list(zip([\"DESCRIPTION INDEX: \" + str(x) for x in sample_indexes], descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report 3 Real and 3 Bogus examples for the dynamic prompt\n",
    "EXAMPLES = [\"<EXAMPLES>\\n\"]\n",
    "for i in range(len(sample_indexes)):\n",
    "    \n",
    "    str_EX = f\"\"\"Example {i+1}:\n",
    "    \"\"\"\n",
    "    all_list = create_ex(sample_indexes[i], True)\n",
    "    all_list.insert(0, str_EX)\n",
    "    all_list.append(descriptions[i])\n",
    "    all\n",
    "    for k in all_list:\n",
    "        EXAMPLES.append(k)\n",
    "EXAMPLES.append(\"\\n</EXAMPLES>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging the experiment\n",
    "models_list = [\"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\"]\n",
    "temp_list = [round(0.2 * i, 1) for i in range(11)]\n",
    "topp_list = [round(0.2 * i, 1) for i in range(6)]\n",
    "## Prepare the variables\n",
    "#timestamp = datetime.datetime.now()\n",
    "#formatted_datetime = timestamp.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "## Log the experiments variables\n",
    "### Create the run name with timestamp\n",
    "for mod in models_list:\n",
    "    for temp in temp_list:\n",
    "        for topp in topp_list:\n",
    "            MODEL = mod\n",
    "            TEMPERATURE = temp\n",
    "            TOP_P = topp\n",
    "            DESCRIPTION = \"Hyperparameter testing with Temperature: \" + str(TEMPERATURE*10) + \" Top_P: \" + str(TOP_P*10) + \" and Model: \" + MODEL\n",
    "\n",
    "            if mod == \"gemini-1.5-flash-001\":\n",
    "                run_name = \"flashtemp\" + str(int(TEMPERATURE*10)) + \"topp\" + str(int(TOP_P*10))\n",
    "            else:\n",
    "                run_name = \"pro15temp\" + str(int(TEMPERATURE*10)) + \"topp\" + str(int(TOP_P*10))\n",
    "            # Build the experimentation variables\n",
    "            exp_vars = build_experiment_vars(description=DESCRIPTION, model=MODEL, temperature=TEMPERATURE, top_p=TOP_P)\n",
    "            # Start the run\n",
    "            print(run_name)\n",
    "            aiplatform.start_run(run_name)\n",
    "            # Log the experiment variables\n",
    "            batch_sample = random.sample(range(0, len(batch_index)),50)\n",
    "            aiplatform.log_params(exp_vars)\n",
    "            pred_df = build_run_batch(bq_client, batch_sample, labels_ref, PROJECT_ID, DATASET_ID, run_name, MODEL, stat_prompt, EXAMPLES, TEMPERATURE, TOP_P)\n",
    "            aiplatform.end_run()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
